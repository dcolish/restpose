#!/usr/bin/env python
#
# Download some sample texts from wikipedia for various languages.

# Copyright (c) 2011 Richard Boulton
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to
# deal in the Software without restriction, including without limitation the
# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
# sell copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
# IN THE SOFTWARE.

# Configure this to control the languages retrieved.
languages = (
             # Xapian built-in languages
	     'da', 'nl', 'en', 'de', 'es', 'fi', 'fr', 'hu', 'it', 'no', 'pt',
             'ru', 'ro', 'sv', 'tr',
             
             # CJK
             'ko', 'zh', 'ja',
	    )

import json
import urllib
import time
import lxml.etree
import os

def get_url(lang, path):
    time.sleep(0.5)
    url = 'http://%s.wikipedia.org%s' % (lang, path)
    return json.loads(urllib.urlopen(url).read())

def get_random_page_ids(lang):
    while True:
        data = get_url(lang, '/w/api.php?action=query&list=random&rnnamespace=0&rnlimit=10&format=json&export=')
        for item in data['query']['random']:
            yield item['id'], item['title']

def get_page_text(lang, id):
    data = get_url(lang, '/w/api.php?action=query&prop=revisions&pageids=%s&rvprop=content&format=json&rvparse=1' % id)
    text = data['query']['pages'][unicode(id)]['revisions'][0]['*']
    tree = lxml.etree.fromstring(u'<root>' + text + u'</root>')
    return tree

def get_random_pages(lang):
    for id, title in get_random_page_ids(lang):
        tree = get_page_text(lang, id)
        text = tree.xpath("string()")
        yield title, text + "\n"

def save_text(lang, target_size, destdir):
    alltext = ''
    for title, text in get_random_pages(lang):
        alltext += title + " " + text
        print "%s: %d/%d" % (title, len(alltext), target_size)
        if len(alltext) >= target_size:
            break

    fd = open(os.path.join(destdir, "text_" + lang), "w")
    fd.write(alltext.encode('utf8'))
    fd.close()

if __name__ == '__main__':
    destdir = os.path.join(
        os.path.dirname(os.path.dirname(
            os.path.realpath(__file__))),
        "lang_samples"
    )
    if not os.path.isdir(destdir):
        os.makedirs(destdir)
    for lang in languages:
        save_text(lang, 500 * 1024, destdir)
